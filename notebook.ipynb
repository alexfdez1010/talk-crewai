{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Developing AI Agents with CrewAI in Python**  \n",
    "\n",
    "In this presentation, we will explore how to **develop AI agents** using the **CrewAI** framework in Python. The presentation is structured with theoretical explanations and **fully executable code examples** in Markdown and Python.  \n",
    "\n",
    "The following topics will be covered:  \n",
    "- **Introduction to CrewAI**: What is CrewAI, and when should it be used? Benefits in automation and multi-agent collaboration.  \n",
    "- **Setting up the Environment**: Installing CrewAI, configuring Google AI Studio with the **Gemini 2.0 Flash** model, and using **LiteLLM** for model integration.  \n",
    "- **Core Concepts of CrewAI**: Understanding `Crew`, `Agent`, `Tools`, and `Flows`.  \n",
    "- **Practical Examples**: From a basic agent to a team of multiple agents using customized tools and structured workflows.  \n",
    "- **Best Practices**: Recommendations for **optimizing performance, managing tools/workflows efficiently, and scaling** to larger projects.  \n",
    "\n",
    "## **1. Introduction to CrewAI**  \n",
    "\n",
    "### **What is CrewAI?**  \n",
    "CrewAI is an open-source framework that enables the **orchestration of AI agent teams** that collaborate with each other. Each agent is an **LLM-powered entity** with a specific **role and goal**, and CrewAI allows them to work **autonomously** to complete complex tasks.  \n",
    "\n",
    "Instead of using a **single AI assistant**, CrewAI lets multiple agents collaborate, each specializing in a different role (*role-playing*), **communicating and cooperating** to solve problems more effectively.  \n",
    "\n",
    "### **When is CrewAI useful?**  \n",
    "CrewAI is ideal for scenarios where **a single AI model is insufficient or inefficient**. Some use cases include:  \n",
    "- **Automated research pipelines**: One agent **searches for information**, another **analyzes data**, and another **summarizes** the findings.  \n",
    "- **Intelligent assistants**: A **multi-functional AI assistant** where different agents handle **specialized queries** (e.g., a coding assistant, a finance analyst, a medical expert).  \n",
    "- **Workflow automation**: Complex tasks can be **divided into subtasks**, handled by different agents (like a human team with different roles).  \n",
    "\n",
    "### **Key Benefits of CrewAI for Automation and Collaboration**  \n",
    "- **Specialized collaboration**: Each agent can have a **unique role and expertise**, allowing multiple **perspectives and skills** to be applied to a problem simultaneously.  \n",
    "- **Automating complex tasks**: A **Crew** (team) of agents can **break down complex objectives** into manageable steps and delegate them to the most suitable agent.  \n",
    "- **Integration with external tools**: CrewAI **supports custom tools** (*Tools*), such as **web searches, data retrieval, API interactions**, and **executing Python code**, making agents much more powerful.  \n",
    "- **Scalability and flexibility**: Thanks to its modular design, you can **easily add more agents**, **switch LLMs**, or **adjust workflows** without rewriting everything. Additionally, with **LiteLLM**, you can **switch between AI providers (Google, OpenAI, Anthropic, etc.)** with minimal configuration changes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Setting Up the Environment**  \n",
    "\n",
    "Before developing with CrewAI, we need to **set up the Python environment**, install dependencies, and configure **LLM access (Google Gemini 2.0 Flash via LiteLLM)**. We are using for management of dependencies `uv`. To install all dependencies con you can execute the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m268 packages\u001b[0m \u001b[2min 0.46ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m262 packages\u001b[0m \u001b[2min 0.04ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you doesn't have installed `uv` you can get the information to install it on [https://docs.astral.sh/uv/getting-started/installation](https://docs.astral.sh/uv/getting-started/installation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Configuring Google AI Studio and Gemini 2.0 Flash**  \n",
    "\n",
    "CrewAI integrates with **Google AI Studio** (**Vertex AI**) via **LiteLLM**. If you have access to **Gemini 2.0 Flash**, follow these steps to use it:  \n",
    "\n",
    "#### **1. Obtain Google AI Studio Credentials**  \n",
    "Log in to **Google AI Studio** and obtain API access. You have two options:  \n",
    "- **API Key**: If available, generate an API key for **Google Gemini**.  \n",
    "- **Service Account JSON**: Create a **service account** with **Vertex AI permissions** and **download the JSON key file**.  \n",
    "\n",
    "#### **2. Set Up Environment Variables**  \n",
    "\n",
    "Change the file `.env.example` to `.env` and set `GEMINI_API_KEY` to your API key.\n",
    "\n",
    "#### **3. Check if it works**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 + 1 = 2\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from crewai import LLM\n",
    "\n",
    "gemini_model = LLM(\n",
    "    model=\"gemini/gemini-2.0-flash\", \n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "gemini_model.call(\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the previous code works well you are set for the rest of the notebook.\n",
    "\n",
    "## **3. Core Concepts of CrewAI**  \n",
    "\n",
    "### **Crew (Team of AI Agents)**  \n",
    "A **Crew** is a **team of AI agents** working together on a project or task.  \n",
    "In CrewAI, a `Crew` object **groups multiple agents and defines how they interact**.  \n",
    "\n",
    "#### **Key Features of a Crew**  \n",
    "- A `Crew` contains a **list of agents** (`agents`) and **tasks** (`tasks`) assigned to them.  \n",
    "- The **process mode** determines how tasks are executed:\n",
    "  - **Sequential** (`Process.sequential`): Agents execute tasks **one after another**, in a predefined order.\n",
    "  - **Hierarchical** (`Process.hierarchical`): A **manager agent** dynamically assigns tasks to other agents.\n",
    "\n",
    "A **Crew is the highest-level entity in CrewAI**, orchestrating AI agents to complete a **complex goal**.\n",
    "\n",
    "### **Agent (AI Entity)**  \n",
    "An **Agent** is an **AI-powered entity** that performs a specific role in CrewAI.  \n",
    "\n",
    "#### **Key Features of an Agent**  \n",
    "- **`role` (role):** Short description of the agent’s purpose, e.g., *\"Technical Researcher\"*, *\"Data Analyst\"*.  \n",
    "- **`goal` (goal):** Defines what the agent should accomplish.  \n",
    "- **`backstory` (background story):** Optional additional context (e.g., *\"You are a finance analyst with 10 years of experience...\"*).  \n",
    "- **Assigned LLM:** The AI model used by the agent (e.g., `\"gemini/gemini-2.0-flash\"`).  \n",
    "- **Tools available:** Each agent can use external **tools** to enhance its abilities (e.g., search engines, data retrieval APIs).  \n",
    "\n",
    "Each **Agent behaves autonomously**, deciding how to complete its tasks based on its **role, goal, tools, and available knowledge**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tools (Custom Capabilities for Agents)**  \n",
    "\n",
    "**Tools** are external functions or actions that **enhance an agent's capabilities**. Instead of relying solely on **LLM-generated knowledge**, agents can **use tools** to:  \n",
    "- **Search the web**  \n",
    "- **Perform mathematical calculations**  \n",
    "- **Query databases**  \n",
    "- **Execute Python scripts**  \n",
    "- **Retrieve and process external data (APIs, files, etc.)**  \n",
    "\n",
    "**How do Tools work?**  \n",
    "- CrewAI provides **built-in tools** (e.g., **Google search, file management, code execution**).  \n",
    "- Developers can **create custom tools** for **specific needs**.  \n",
    "- Agents **decide when to use tools**: CrewAI **injects tool descriptions** into the agent’s prompt so that the LLM can determine **when to invoke a tool**.  \n",
    "\n",
    "### **Flows (Workflow Automation)**  \n",
    "\n",
    "**Flows** represent **structured and event-driven workflows** in CrewAI.  \n",
    "\n",
    "While a **Crew** organizes **AI collaboration**, a **Flow** defines **the sequence and logic** behind the execution of tasks.  \n",
    "\n",
    "**Key features of Flows**:  \n",
    "- **Each Flow is a class** inheriting from `Flow`.  \n",
    "- **Flows have multiple steps**, each marked with decorators:\n",
    "  - `@start()` → Defines the **entry point** of the workflow.  \n",
    "  - `@listen(event)` → Defines a **step triggered by a previous event**.  \n",
    "  - `@router(event)` → **Conditional branching**, allowing different execution paths.  \n",
    "- **Flows can include both AI agents and Python logic**, combining **natural language reasoning** with **programmatic decision-making**.  \n",
    "- **State management** (`self.state`) allows storing intermediate results.  \n",
    "- A Flow is executed using `flow.kickoff()`, triggering the `@start()` method and sequentially executing subsequent steps.\n",
    "\n",
    "**How it works:**  \n",
    "1. The **Researcher agent** gathers information.  \n",
    "2. The **Analyst agent** receives this data and creates a summary report.  \n",
    "3. **CrewAI executes tasks sequentially**, with `Process.sequential`.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Example 3: Creating a Custom Tool for Mathematical Calculations**  \n",
    "\n",
    "CrewAI allows **custom tools** to be created, expanding agent capabilities.  \n",
    "\n",
    "Let’s define a **simple tool** for **summing a list of numbers**:  \n",
    "\n",
    "```python\n",
    "from crewai.tools import tool\n",
    "\n",
    "@tool(\"AddNumbers\")\n",
    "def add_numbers(numbers: list) -> float:\n",
    "    \"\"\"Adds a list of numbers and returns the result.\"\"\"\n",
    "    return sum(numbers)\n",
    "\n",
    "# Create an agent that uses this tool\n",
    "math_agent = Agent(\n",
    "    role=\"Mathematical Expert\",\n",
    "    goal=\"Help with mathematical calculations and number analysis\",\n",
    "    tools=[add_numbers],  # Attach the custom tool to the agent\n",
    "    llm=\"openai/gpt-4\"\n",
    ")\n",
    "\n",
    "# Example usage: The agent calculates the sum of a list of numbers\n",
    "question = \"What is the sum of [10, 20, 30, 40]?\"\n",
    "response = math_agent.run(question)\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Agent's Response:\", response)\n",
    "```\n",
    "\n",
    "**How it works:**  \n",
    "- We define `@tool(\"AddNumbers\")`, which makes `add_numbers()` available as a **CrewAI Tool**.  \n",
    "- The `math_agent` has **this tool assigned** (`tools=[add_numbers]`).  \n",
    "- If the agent **detects** a sum operation, it will **invoke** `add_numbers()` **instead of relying on its LLM**.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Example 4: Using Flows to Structure a Task Sequence**  \n",
    "\n",
    "Let’s define a **Flow** where:  \n",
    "1. **Step 1:** Get a **random city name**.  \n",
    "2. **Step 2:** Get a **fun fact about that city**.  \n",
    "\n",
    "```python\n",
    "from crewai.flow.flow import Flow, start, listen\n",
    "from litellm import completion  # LiteLLM function for direct calls\n",
    "\n",
    "class CityFlow(Flow):\n",
    "    model = \"openai/gpt-3.5-turbo\"\n",
    "\n",
    "    @start()\n",
    "    def get_random_city(self):\n",
    "        \"\"\"Step 1: Fetch a random city name.\"\"\"\n",
    "        print(\"Fetching a random city...\")\n",
    "        response = completion(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Give me a random city name.\"}]\n",
    "        )\n",
    "        city = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        return {\"city\": city}\n",
    "\n",
    "    @listen(get_random_city)\n",
    "    def get_fun_fact(self, data):\n",
    "        \"\"\"Step 2: Retrieve a fun fact about the given city.\"\"\"\n",
    "        city = data[\"city\"]\n",
    "        print(f\"City chosen: {city}. Fetching a fun fact...\")\n",
    "        prompt = f\"Tell me an interesting fact about {city}.\"\n",
    "        response = completion(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        fact = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        return f\"**{city}**: {fact}\"\n",
    "\n",
    "# Execute the Flow\n",
    "flow = CityFlow()\n",
    "final_result = flow.kickoff()\n",
    "\n",
    "print(\"\\nFinal Result:\", final_result)\n",
    "```\n",
    "\n",
    "**Expected Output Example:**  \n",
    "```\n",
    "City chosen: Tokyo.  \n",
    "Final Result: **Tokyo**: Tokyo is the most populated city in the world, with over 37 million people in its metropolitan area.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "This **completes** the translation of **all content** into **English**! 🚀  \n",
    "You now have a **fully structured Jupyter Notebook presentation** in **CrewAI**.  \n",
    "\n",
    "Would you like **any modifications or additional details**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Practical Examples**  \n",
    "\n",
    "## **Example 1: Basic crew with only one task and one agent**  \n",
    "\n",
    "Let’s create a **simple CrewAI agent** that uses **Google Gemini 2.0 Flash** to **answer questions**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cáceres is a city and a province in Spain. Therefore, the capital of Cáceres is, drum roll please... Cáceres! I know, mind-blowing, right? Try to contain your excitement.\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "\n",
    "assistant = Agent(\n",
    "    role=\"General Assistant\",\n",
    "    goal=\"Answer general knowledge questions accurately and concisely\",\n",
    "    llm=\"gemini/gemini-2.0-flash\",\n",
    "    backstory=\"You are a general assistant that answers general knowledge questions accurately and concisely in a sarcastic and funny way.\"\n",
    ")\n",
    "\n",
    "question = input()\n",
    "\n",
    "task = Task(\n",
    "    agent=assistant,\n",
    "    description=question,\n",
    "    expected_output=\"The user should laugh a lot with the answer\"\n",
    ")\n",
    "\n",
    "crew = Crew(agents=[assistant], tasks=[task])\n",
    "\n",
    "# Run the agent to generate a response\n",
    "response = crew.kickoff()\n",
    "print(response.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Creating a Multi-Agent Crew\n",
    "\n",
    "Let’s create a research pipeline where:\n",
    "\n",
    "- A Researcher agent gathers information on a given topic.\n",
    "- An Analyst agent summarizes the information into a report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import SerperDevTool, WebsiteSearchTool\n",
    "\n",
    "search_tool = SerperDevTool()\n",
    "\n",
    "researcher = Agent(\n",
    "    role=\"Researcher\",\n",
    "    goal=\"Find and summarize relevant information about {topic}\",\n",
    "    backstory=\"You are a researcher specializing in gathering the latest information on a given topic.\",\n",
    "    llm=\"gemini/gemini-2.0-flash\",\n",
    "    tools=[search_tool]\n",
    ")\n",
    "\n",
    "analyst = Agent(\n",
    "    role=\"Analyst\",\n",
    "    goal=\"Review collected information and generate a clear summary on {topic}\",\n",
    "    backstory=\"You are an analyst with excellent summarization skills.\",\n",
    "    llm=\"gemini/gemini-2.0-flash\"   \n",
    ")\n",
    "\n",
    "research_task = Task(\n",
    "    description=\"Research the topic '{topic}' and list key findings.\",\n",
    "    expected_output=\"A list of key findings about {topic}.\",\n",
    "    agent=researcher\n",
    ")\n",
    "\n",
    "summary_task = Task(\n",
    "    description=\"Summarize the collected research into a concise report.\",\n",
    "    expected_output=\"A brief report summarizing the findings on {topic}.\",\n",
    "    agent=analyst\n",
    ")\n",
    "\n",
    "# Create a Crew with both agents, running tasks sequentially\n",
    "team = Crew(\n",
    "    agents=[researcher, analyst],\n",
    "    tasks=[research_task, summary_task],\n",
    "    process=Process.sequential, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run the Crew, providing the topic as an input\n",
    "topic = \"Recent advances in artificial intelligence\"\n",
    "results = team.kickoff(inputs={\"topic\": topic})\n",
    "\n",
    "# Print final report\n",
    "print(\"\\n--- Generated Summary ---\")\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
